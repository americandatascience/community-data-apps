{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "401d37f3",
      "metadata": {
        "id": "d79e34f0-a17f-401f-892a-59e52af943a8"
      },
      "source": [
        "# AI Tinkerers Demo: Streaming and Async Calls with LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d5ff177",
      "metadata": {
        "id": "80434a7c-1fb7-4803-9ee5-22154de91819"
      },
      "source": [
        "## 0. Load env vars and set client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe70d9ce",
      "metadata": {
        "id": "cfbcbc08-0118-42f1-b735-3f9ffeadc7ff",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "import dotenv\n",
        "import time\n",
        "\n",
        "# Load environment variables from .env file\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "# Set up the AI21 client\n",
        "client = AI21Client()\n",
        "\n",
        "model = \"jamba-mini-1.6-2025-03\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edea88fa",
      "metadata": {
        "id": "be4648c9-866e-46b5-9205-465beb4ba0e0"
      },
      "source": [
        "## 1. Typical calls to API LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c6a3a0",
      "metadata": {
        "id": "dd8d47d1-8210-4052-b0ef-0b47ba042886",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the system and user messages\n",
        "system = \"You're a data feature enrichment engineer.\"\n",
        "messages = [\n",
        "    ChatMessage(content=system, role=\"system\"),\n",
        "    ChatMessage(content=\"Hello, I need help with enriching CSVs.\", role=\"user\"),\n",
        "]\n",
        "\n",
        "# Start timing the request\n",
        "start_time = time.time()\n",
        "\n",
        "# Make the API call\n",
        "chat_completions = client.chat.completions.create(\n",
        "    messages=messages,\n",
        "    model=model,\n",
        ")\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print the chat completion response\n",
        "print(\"Chat Completion Response:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Role: {chat_completions.choices[0].message.role}\")\n",
        "print(f\"Content: {chat_completions.choices[0].message.content}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Display additional metadata about the response\n",
        "# Using dir() and vars() to safely inspect the object structure\n",
        "print(\"\\nResponse Metadata:\")\n",
        "print(f\"Request Time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Safely access usage information\n",
        "if hasattr(chat_completions, 'usage'):\n",
        "    usage = chat_completions.usage\n",
        "    print(f\"Usage - Prompt Tokens: {usage.prompt_tokens}\")\n",
        "    print(f\"Usage - Completion Tokens: {usage.completion_tokens}\")\n",
        "    print(f\"Usage - Total Tokens: {usage.total_tokens}\")\n",
        "\n",
        "# Print the model name from the request rather than trying to access it from the response\n",
        "print(f\"Model: jamba-mini-1.6-2025-03\")\n",
        "\n",
        "# Print the full response structure for debugging (optional)\n",
        "print(\"\\nFull Response Structure:\")\n",
        "print(f\"Response type: {type(chat_completions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f0dbe6",
      "metadata": {
        "id": "12105379-f6cf-4056-b775-80d9ce5a1768"
      },
      "source": [
        "### Now use this to loop through rows in drug_reviews.csv to extract \"Positive, Negative\" given the text in \"review\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512652ec",
      "metadata": {
        "id": "8fe1daf7-35a9-479d-85f2-31172d05ed16",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for data processing and sentiment analysis\n",
        "import pandas as pd\n",
        "import time\n",
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the drug reviews dataset\n",
        "try:\n",
        "    # Try to load the first few rows to understand the structure\n",
        "    df = pd.read_csv('drug_reviews.csv', nrows=5)\n",
        "    print(f\"Successfully loaded sample from drug_reviews.csv\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    \n",
        "    # Load the full dataset or a subset for processing\n",
        "    # Limiting to 20 rows for demonstration purposes\n",
        "    # Remove the nrows parameter to process the entire file\n",
        "    df = pd.read_csv('drug_reviews.csv', nrows=20)\n",
        "    print(f\"\\nLoaded {len(df)} rows for processing\")\n",
        "    \n",
        "    # Create a new column to store sentiment analysis results\n",
        "    df['sentiment'] = \"\"\n",
        "    \n",
        "    # Set up the AI21 client (using the client already initialized above)\n",
        "    client = AI21Client()\n",
        "    model = \"jamba-mini-1.6-2025-03\"\n",
        "    \n",
        "    # Define the system prompt for sentiment analysis\n",
        "    system_prompt = \"You are a sentiment analysis expert. Analyze the drug review and respond 'Positive' or 'Negative' with reasoning.\"\n",
        "    \n",
        "    # Process each review and extract sentiment\n",
        "    print(\"\\nProcessing reviews for sentiment analysis...\")\n",
        "    \n",
        "    # Track time for performance analysis\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        # Create messages for the API call\n",
        "        messages = [\n",
        "            ChatMessage(content=system_prompt, role=\"system\"),\n",
        "            ChatMessage(content=f\"Analyze the sentiment of this drug review: {row['review']}\", role=\"user\"),\n",
        "        ]\n",
        "        \n",
        "        # Make the API call\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                messages=messages,\n",
        "                model=model,\n",
        "            )\n",
        "            \n",
        "            # Extract the sentiment from the response\n",
        "            sentiment = response.choices[0].message.content.strip()\n",
        "            \n",
        "            # Store the sentiment in the dataframe\n",
        "            df.at[idx, 'sentiment'] = sentiment\n",
        "            \n",
        "            # Add a small delay to avoid rate limiting (if needed)\n",
        "            time.sleep(0.1)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {idx}: {str(e)}\")\n",
        "            df.at[idx, 'sentiment'] = \"Error\"\n",
        "    \n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\nProcessing completed in {elapsed_time:.2f} seconds\")\n",
        "    \n",
        "    # Display the results\n",
        "    print(\"\\nSentiment Analysis Results:\")\n",
        "    print(df[['review', 'sentiment']].head(10))\n",
        "    \n",
        "    # Save the results to a new CSV file\n",
        "    output_file = 'drug_reviews_with_sentiment.csv'\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"\\nResults saved to {output_file}\")\n",
        "    \n",
        "    # Calculate some statistics\n",
        "    sentiment_counts = df['sentiment'].value_counts()\n",
        "    print(\"\\nSentiment Distribution:\")\n",
        "    print(sentiment_counts)\n",
        "    \n",
        "    # Calculate percentage of positive reviews\n",
        "    if len(df) > 0:\n",
        "        positive_percentage = (sentiment_counts.get('Positive', 0) / len(df)) * 100\n",
        "        print(f\"\\nPercentage of Positive Reviews: {positive_percentage:.2f}%\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"Error: drug_reviews.csv file not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb71ebe1",
      "metadata": {
        "id": "f3bcd89b-b054-4b73-a6d9-59df5de9e56d"
      },
      "source": [
        "## 2. Now with streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b487dd05",
      "metadata": {
        "id": "ded5310a-4f00-4dcf-b6aa-b0d6eae654f1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a streaming function to demonstrate real-time responses from the LLM\n",
        "# This builds on the previous section by showing how to stream responses\n",
        "# rather than waiting for the complete response\n",
        "\n",
        "import time\n",
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "\n",
        "# Define the system and user messages (similar to previous example)\n",
        "system = \"You're a data feature enrichment engineer.\"\n",
        "messages = [\n",
        "    ChatMessage(content=system, role=\"system\"),\n",
        "    ChatMessage(content=\"Explain how to enrich a CSV with reviews with sentiment data in 5 steps.\", role=\"user\"),\n",
        "]\n",
        "\n",
        "# Start timing the request\n",
        "start_time = time.time()\n",
        "\n",
        "# Make the streaming API call\n",
        "# The stream=True parameter enables streaming responses\n",
        "print(\"Streaming Response:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Initialize variables to track token usage\n",
        "total_tokens = 0\n",
        "response_content = \"\"\n",
        "\n",
        "# Stream the response\n",
        "for chunk in client.chat.completions.create(\n",
        "    messages=messages,\n",
        "    model=model,\n",
        "    stream=True,\n",
        "):\n",
        "    # Extract and print each chunk of the response as it arrives\n",
        "    if chunk.choices and chunk.choices[0].delta.content:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        print(content, end=\"\", flush=True)\n",
        "        response_content += content\n",
        "        total_tokens += 1  # Approximate token count\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = time.time() - start_time\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "\n",
        "# Display metadata about the streaming response\n",
        "print(\"\\nStreaming Response Metadata:\")\n",
        "print(f\"Request Time: {elapsed_time:.2f} seconds\")\n",
        "print(f\"Approximate Completion Tokens: {total_tokens}\")\n",
        "print(f\"Model: {model}\")\n",
        "\n",
        "# Compare streaming vs non-streaming\n",
        "print(\"\\nAdvantages of Streaming:\")\n",
        "print(\"1. Immediate feedback to users\")\n",
        "print(\"2. Better perceived performance\")\n",
        "print(\"3. Ability to process partial responses\")\n",
        "print(\"4. Can cancel long-running requests early\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "789c0f1a",
      "metadata": {
        "id": "870cd212-015b-4d14-a1ea-5b62e272d616"
      },
      "source": [
        "### Loop through rows in drug_reviews.csv to extract \"Positive, Negative\" given the text in \"review\" column while streaming each one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c73bb4e",
      "metadata": {
        "id": "a93cba7c-ee2c-46af-8a6e-1e118355506f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for streaming sentiment analysis\n",
        "import pandas as pd\n",
        "import time\n",
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the drug reviews dataset\n",
        "try:\n",
        "    # Load the dataset (limited to 20 rows for demonstration)\n",
        "    print(\"Loading drug reviews dataset...\")\n",
        "    df = pd.read_csv('drug_reviews.csv', nrows=20)\n",
        "    print(f\"Loaded {len(df)} rows for processing\")\n",
        "    \n",
        "    # Create a new column to store sentiment analysis results\n",
        "    df['sentiment'] = \"\"\n",
        "    \n",
        "    # Set up the AI21 client (using the client already initialized above)\n",
        "    client = AI21Client()\n",
        "    model = \"jamba-mini-1.6-2025-03\"\n",
        "    \n",
        "    # Define the system prompt for sentiment analysis\n",
        "    system_prompt = \"You are a sentiment analysis expert. Analyze the drug review and respond with 'Positive' or 'Negative' with reasoning.\"\n",
        "    \n",
        "    # Process each review and extract sentiment with streaming\n",
        "    print(\"\\nProcessing reviews with streaming sentiment analysis...\")\n",
        "    \n",
        "    # Track time for performance analysis\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        # Create messages for the API call\n",
        "        messages = [\n",
        "            ChatMessage(content=system_prompt, role=\"system\"),\n",
        "            ChatMessage(content=f\"Analyze the sentiment of this drug review: {row['review']}\", role=\"user\"),\n",
        "        ]\n",
        "        \n",
        "        # Make the streaming API call\n",
        "        try:\n",
        "            print(f\"\\nAnalyzing review {idx+1}/{len(df)}: \", end=\"\", flush=True)\n",
        "            \n",
        "            # Initialize variables to collect the streamed response\n",
        "            full_response = \"\"\n",
        "            \n",
        "            # Stream the response\n",
        "            for chunk in client.chat.completions.create(\n",
        "                messages=messages,\n",
        "                model=model,\n",
        "                stream=True,\n",
        "            ):\n",
        "                # Extract and print each chunk of the response as it arrives\n",
        "                if chunk.choices and chunk.choices[0].delta.content:\n",
        "                    content = chunk.choices[0].delta.content\n",
        "                    print(content, end=\"\", flush=True)\n",
        "                    full_response += content\n",
        "            \n",
        "            # Store the sentiment in the dataframe\n",
        "            df.at[idx, 'sentiment'] = full_response.strip()\n",
        "            \n",
        "            # Add a small delay to avoid rate limiting (if needed)\n",
        "            time.sleep(0.1)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing row {idx}: {str(e)}\")\n",
        "            df.at[idx, 'sentiment'] = \"Error\"\n",
        "    \n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\n\\nProcessing completed in {elapsed_time:.2f} seconds\")\n",
        "    \n",
        "    # Display the results\n",
        "    print(\"\\nSentiment Analysis Results:\")\n",
        "    print(df[['review', 'sentiment']].head(10))\n",
        "    \n",
        "    # Save the results to a new CSV file\n",
        "    output_file = 'drug_reviews_with_streaming_sentiment.csv'\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"\\nResults saved to {output_file}\")\n",
        "    \n",
        "    # Calculate some statistics\n",
        "    sentiment_counts = df['sentiment'].value_counts()\n",
        "    print(\"\\nSentiment Distribution:\")\n",
        "    print(sentiment_counts)\n",
        "    \n",
        "    # Calculate percentage of positive reviews\n",
        "    if len(df) > 0:\n",
        "        positive_count = sum(1 for s in df['sentiment'] if s.lower().startswith('positive'))\n",
        "        positive_percentage = (positive_count / len(df)) * 100\n",
        "        print(f\"\\nPercentage of Positive Reviews: {positive_percentage:.2f}%\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"Error: drug_reviews.csv file not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38605ed0",
      "metadata": {
        "id": "fd9dc668-44e8-44c3-b7f4-389d47072ea1"
      },
      "source": [
        "## 3. Now with Concurrent Calls with Async Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99eca11e",
      "metadata": {
        "id": "bd59ce22-288e-448c-a2cf-d8bf402d01f9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for async operations\n",
        "import asyncio\n",
        "import time\n",
        "from ai21 import AsyncAI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "\n",
        "# Define a function to make async API calls to AI21\n",
        "async def make_async_call(client, messages, model_name):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Make the async API call\n",
        "    response = await client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=model_name,\n",
        "    )\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    # Return both the response and timing information\n",
        "    return response, elapsed_time\n",
        "\n",
        "# Set up the async client using environment variables (already loaded above)\n",
        "async_client = AsyncAI21Client()\n",
        "\n",
        "# Define different prompts to demonstrate parallel processing\n",
        "system_prompt1 = \"You're a data feature enrichment engineer.\"\n",
        "system_prompt2 = \"You're a customer support specialist.\"\n",
        "system_prompt3 = \"You're a technical documentation writer.\"\n",
        "\n",
        "# Create message sets for each prompt\n",
        "messages1 = [\n",
        "    ChatMessage(content=system_prompt1, role=\"system\"),\n",
        "    ChatMessage(content=\"Hello, I need help with enriching CSVs.\", role=\"user\"),\n",
        "]\n",
        "messages2 = [\n",
        "    ChatMessage(content=system_prompt2, role=\"system\"),\n",
        "    ChatMessage(content=\"Hello, I need help with enriching CSVs.\", role=\"user\"),\n",
        "]\n",
        "messages3 = [\n",
        "    ChatMessage(content=system_prompt3, role=\"system\"),\n",
        "    ChatMessage(content=\"Hello, I need help with enriching CSVs.\", role=\"user\"),\n",
        "]\n",
        "\n",
        "# Define the main async function to run multiple calls concurrently\n",
        "async def run_concurrent_calls():\n",
        "    # Start timing the entire concurrent operation\n",
        "    total_start_time = time.time()\n",
        "    \n",
        "    # Run all three API calls concurrently\n",
        "    tasks = [\n",
        "        make_async_call(async_client, messages1, model),\n",
        "        make_async_call(async_client, messages2, model),\n",
        "        make_async_call(async_client, messages3, model),\n",
        "    ]\n",
        "    \n",
        "    # Gather results from all tasks\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    \n",
        "    total_elapsed_time = time.time() - total_start_time\n",
        "    \n",
        "    # Print results from each call\n",
        "    for i, (response, call_time) in enumerate(results, 1):\n",
        "        print(f\"\\nResponse {i}:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Role: {response.choices[0].message.role}\")\n",
        "        print(f\"Content: {response.choices[0].message.content}\")\n",
        "        print(f\"Request Time: {call_time:.2f} seconds\")\n",
        "        \n",
        "        # Print usage information\n",
        "        if hasattr(response, 'usage'):\n",
        "            usage = response.usage\n",
        "            print(f\"Usage - Prompt Tokens: {usage.prompt_tokens}\")\n",
        "            print(f\"Usage - Completion Tokens: {usage.completion_tokens}\")\n",
        "            print(f\"Usage - Total Tokens: {usage.total_tokens}\")\n",
        "    \n",
        "    print(\"\\nConcurrent Execution Summary:\")\n",
        "    print(f\"Total time for all 3 requests: {total_elapsed_time:.2f} seconds\")\n",
        "    print(f\"Average time per request if sequential: {sum(time for _, time in results)/len(results):.2f} seconds\")\n",
        "    print(f\"Time saved with async: {(sum(time for _, time in results) - total_elapsed_time):.2f} seconds\")\n",
        "\n",
        "# Run the async function\n",
        "await run_concurrent_calls()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d806f6c0",
      "metadata": {
        "id": "ba210f7b-c7d9-4343-baa7-51a937bc95a0"
      },
      "source": [
        "### Concurrently extract \"Positive, Negative\" with reasoning given the text in \"review\" column in drug_reviews.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3e69f7",
      "metadata": {
        "id": "729a0c46-6b82-4dc5-ab84-c5469a0d731b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for async sentiment analysis\n",
        "import pandas as pd\n",
        "import asyncio\n",
        "import time\n",
        "from ai21 import AsyncAI21Client\n",
        "from ai21.models.chat import ChatMessage\n",
        "from tqdm.asyncio import tqdm_asyncio\n",
        "\n",
        "# Define an async function to process a single review\n",
        "async def process_review(client, model, review, idx, total):\n",
        "    \"\"\"\n",
        "    Process a single drug review for sentiment analysis using async API calls.\n",
        "    \n",
        "    Args:\n",
        "        client: The AsyncAI21Client instance\n",
        "        model: The AI model to use\n",
        "        review: The text of the review to analyze\n",
        "        idx: The index of the current review\n",
        "        total: The total number of reviews to process\n",
        "        \n",
        "    Returns:\n",
        "        The sentiment analysis result as a string\n",
        "    \"\"\"\n",
        "    # Define the system prompt for sentiment analysis\n",
        "    system_prompt = \"You are a sentiment analysis expert. Analyze the drug review and respond 'Positive' or 'Negative' with reasoning.\"\n",
        "    \n",
        "    # Create messages for the API call\n",
        "    messages = [\n",
        "        ChatMessage(content=system_prompt, role=\"system\"),\n",
        "        ChatMessage(content=f\"Analyze the sentiment of this drug review: {review}\", role=\"user\"),\n",
        "    ]\n",
        "    \n",
        "    # Make the API call with streaming\n",
        "    try:\n",
        "        print(f\"\\nAnalyzing review {idx+1}/{total}: \", end=\"\", flush=True)\n",
        "        \n",
        "        # Initialize variable to collect the streamed response\n",
        "        full_response = \"\"\n",
        "        \n",
        "        # Stream the response\n",
        "        async for chunk in await client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=model,\n",
        "            stream=True,\n",
        "        ):\n",
        "            # Extract and print each chunk of the response as it arrives\n",
        "            if chunk.choices and chunk.choices[0].delta.content:\n",
        "                content = chunk.choices[0].delta.content\n",
        "                print(content, end=\"\", flush=True)\n",
        "                full_response += content\n",
        "        \n",
        "        # Return the sentiment analysis result\n",
        "        return full_response.strip()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing review {idx+1}: {str(e)}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# Define the main async function to process all reviews concurrently\n",
        "async def process_reviews_concurrently(df, batch_size=5):\n",
        "    \"\"\"\n",
        "    Process multiple reviews concurrently in batches using async API calls.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame containing the reviews to process\n",
        "        batch_size: Number of reviews to process concurrently in each batch\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (processed DataFrame, elapsed time)\n",
        "    \"\"\"\n",
        "    # Set up the async client\n",
        "    async_client = AsyncAI21Client()\n",
        "    model = \"jamba-mini-1.6-2025-03\"\n",
        "    \n",
        "    # Create a new column to store sentiment analysis results\n",
        "    df['sentiment'] = \"\"\n",
        "    \n",
        "    # Track time for performance analysis\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Process reviews in batches to avoid overwhelming the API\n",
        "    for i in range(0, len(df), batch_size):\n",
        "        batch_df = df.iloc[i:i+batch_size]\n",
        "        \n",
        "        # Create tasks for concurrent processing\n",
        "        tasks = [\n",
        "            process_review(\n",
        "                async_client, \n",
        "                model, \n",
        "                row['review'], \n",
        "                idx, \n",
        "                len(df)\n",
        "            ) for idx, row in batch_df.iterrows()\n",
        "        ]\n",
        "        \n",
        "        # Process the batch concurrently and get results\n",
        "        results = await tqdm_asyncio.gather(*tasks)\n",
        "        \n",
        "        # Store results in the dataframe\n",
        "        for (idx, _), sentiment in zip(batch_df.iterrows(), results):\n",
        "            df.at[idx, 'sentiment'] = sentiment\n",
        "    \n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return df, elapsed_time\n",
        "\n",
        "# Main execution function\n",
        "async def main():\n",
        "    \"\"\"\n",
        "    Main function to load data, process reviews, and save results.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the drug reviews dataset (limited to 20 rows for demonstration)\n",
        "        print(\"Loading drug reviews dataset...\")\n",
        "        df = pd.read_csv('drug_reviews.csv', nrows=20)\n",
        "        print(f\"Loaded {len(df)} rows for processing\")\n",
        "        \n",
        "        # Process the reviews concurrently\n",
        "        print(\"\\nProcessing reviews with concurrent streaming sentiment analysis...\")\n",
        "        result_df, elapsed_time = await process_reviews_concurrently(df)\n",
        "        \n",
        "        print(f\"\\n\\nProcessing completed in {elapsed_time:.2f} seconds\")\n",
        "        \n",
        "        # Display the results\n",
        "        print(\"\\nSentiment Analysis Results:\")\n",
        "        print(result_df[['review', 'sentiment']].head(10))\n",
        "        \n",
        "        # Save the results to a new CSV file\n",
        "        output_file = 'drug_reviews_with_concurrent_sentiment.csv'\n",
        "        result_df.to_csv(output_file, index=False)\n",
        "        print(f\"\\nResults saved to {output_file}\")\n",
        "        \n",
        "        # Calculate some statistics\n",
        "        positive_count = sum(1 for s in result_df['sentiment'] if 'positive' in s.lower())\n",
        "        positive_percentage = (positive_count / len(result_df)) * 100\n",
        "        print(f\"\\nPercentage of Positive Reviews: {positive_percentage:.2f}%\")\n",
        "        \n",
        "        # Compare with previous non-concurrent approach\n",
        "        print(\"\\nPerformance Comparison:\")\n",
        "        print(f\"Concurrent processing time: {elapsed_time:.2f} seconds\")\n",
        "        print(\"Non-concurrent processing time from previous cell: ~14 seconds\")\n",
        "        print(f\"Speed improvement: ~{14/elapsed_time:.1f}x faster with concurrent processing\")\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: drug_reviews.csv file not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {str(e)}\")\n",
        "\n",
        "# Run the main async function\n",
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94439874",
      "metadata": {
        "id": "f3adb9c9-42be-45ad-b8a9-67b51b7c7cfc",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
